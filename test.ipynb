{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOClC+hFpCExdbGiCZfckV4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syx1990/deep-learning/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQU1-quOuOOB",
        "outputId": "0ebdfc46-a55d-4efe-b3fc-7066fc496d1c"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# !/usr/bin/python3\n",
        "# author by : yuxiangShi\n",
        "# tell  by: 18538187569\n",
        "# desc by: 基础知识记录和回顾\n",
        "\n",
        "# 导入需要的包\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 输出版本号\n",
        "print(tf.__version__)\n",
        "\n",
        "# 张量（Tensor）:多维数组（列表） 阶：张量的维数，张量可以表示0阶到n阶数组（列表）\n",
        "\n",
        "# 维数 阶 名字 例子\n",
        "# 0-D 0 标量 scalar s=1 2 3\n",
        "# 1-D 1 向量 vector v=[1, 2, 3]\n",
        "# 2-D 2 矩阵 matrix m=[[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
        "# n-D n 张量 tensor t=[ [ [\n",
        "# n个\n",
        "\n",
        "# 数据类型\n",
        "# tf.int, tf.float\n",
        "#tf.int 32, tf.float 32, tf.float 64\n",
        "# tf.bool\n",
        "# tf.constant([True, False])\n",
        "# tf.string\n",
        "# tf.constant(“Hello, world!”)\n",
        "\n",
        "# 创建一个张量\n",
        "a = tf.constant([1,5],dtype=tf.int64)\n",
        "print(\"输出张量的内容：\",a)\n",
        "print(\"输出张量的类型：\",a.dtype)\n",
        "print(\"输出张量的形状：\",a.shape)\n",
        "\n",
        "# 将numpy类型转换成Tensor(张量)\n",
        "b = np.arange(0,5)\n",
        "c= tf.convert_to_tensor(b,dtype=tf.int64)\n",
        "print(\"输出numpy类型：\",b)\n",
        "print(\"将numpy类型转换成Tensor：\",c)\n",
        "\n",
        "#创建全为0的张量\n",
        "#tf. zeros(维度) 创建全为1的张量\n",
        "#tf. ones(维度) 创建全为指定值的张量\n",
        "#tf. fill(维度，指定值)\n",
        "#维度：\n",
        "#一维 直接写个数\n",
        "#二维 用 [行，列]\n",
        "#多维 用 [n,m,j,k……]\n",
        "\n",
        "# 案例\n",
        "e = tf.zeros([2,3])\n",
        "f = tf.ones(4)\n",
        "g = tf.fill([2,2],9)\n",
        "\n",
        "print(\"创建一个两行三列的张量：\",e)\n",
        "print(\"创建四行为1的张量：\",f)\n",
        "print(\"创建两行两例为9的张量：\",g)\n",
        "\n",
        "# 生成正态分布的随机数，默认均值为0，标准差为1\n",
        "# tf. random.normal (维度，mean=均值，stddev=标准差) 生成截断式正态分布的随机数\n",
        "# tf. random.truncated_normal (维度，mean=均值，stddev=标准差) 在tf.truncated_normal中如果随机生成数据的取值在（μ-2σ，μ+2σ）之外\n",
        "# 则重新进行生成，保证了生成值在均值附近。\n",
        "# μ：均值， σ：标准差\n",
        "\n",
        "d1 = tf.random.normal([2,2],mean=0.5,stddev=1)\n",
        "print(\"生成截断式正态分布的随机数:\",d1)\n",
        "\n",
        "e1 = tf.random.truncated_normal([2,2],mean=0.5,stddev=1)\n",
        "print(\"生成值在均值附近的正态分布的随机数:\",e1)\n",
        "\n",
        "# 生成均匀分布随机数 [ minval, maxval )\n",
        "# tf. random. uniform(维度，minval=最小值，maxval=最大值)\n",
        "\n",
        "f1 = tf.random.uniform([2,2],minval=0,maxval=1)\n",
        "\n",
        "print(\"生成均匀分布随机数:\",f1)\n",
        "\n",
        "# 常用函数\n",
        "# 强制tensor转换为该数据类型\n",
        "# tf.cast (张量名，dtype=数据类型) 计算张量维度上元素的最小值\n",
        "# tf.reduce_min (张量名) 计算张量维度上元素的最大值\n",
        "# tf.reduce_max (张量名)\n",
        "# 理解axis\n",
        "# 在一个二维张量或数组中，可以通过调整 axis 等于0或1 控制执行维度。\n",
        "# axis=0代表跨行（经度，down)，而axis=1代表跨列（纬度，across)\n",
        "# 如果不指定axis，则所有元素参与计算。\n",
        "#  计算张量沿着指定维度的平均值\n",
        "# tf.reduce_mean (张量名，axis=操作轴)  计算张量沿着指定维度的和\n",
        "# tf.reduce_sum (张量名，axis=操作轴)\n",
        "\n",
        "x1 = tf.constant([1,2,3],dtype=tf.float64)\n",
        "print(\"输出x1的结果：\",x1)\n",
        "\n",
        "x2 = tf.cast(x1,tf.int32)\n",
        "print(\"强制转换成整型：\",x2)\n",
        "print(\"取出最小的值：\",tf.reduce_min(x2))\n",
        "print(\"取出最大的值：\",tf.reduce_max(x2))\n",
        "\n",
        "# 计算张量沿着指定维度的平均值\n",
        "x = tf.constant([[1,2,3],[2,2,3]])\n",
        "print(\"输出x的结果:\",x)\n",
        "print(\"求x的平均值:\",tf.reduce_mean(x))\n",
        "print(\"求x的总和:\",tf.reduce_sum(x,axis=1))\n",
        "\n",
        "# tf.Variable () 将变量标记为“可训练”，被标记的变量会在反向传播\n",
        "# 中记录梯度信息。神经网络训练中，常用该函数标记待训练参数。\n",
        "\n",
        "w = tf.Variable(tf.random.normal([2,2],mean=0,stddev=1))\n",
        "\n",
        "print(\"可训练的：\",w)\n",
        "\n",
        "# TensorFlow中的数学运算\n",
        "\n",
        "# 对应元素的四则运算：tf.add，tf.subtract，tf.multiply，tf.divide\n",
        "# 平方、次方与开方： tf.square，tf.pow，tf.sqrt\n",
        "# 矩阵乘：tf.matmul\n",
        "# 实现两个张量的对应元素相加\n",
        "# tf.add (张量1，张量2)\n",
        "# 实现两个张量的对应元素相减\n",
        "# tf.subtract (张量1，张量2)\n",
        "# 实现两个张量的对应元素相乘\n",
        "# tf.multiply (张量1，张量2)\n",
        "# 实现两个张量的对应元素相除\n",
        "# tf.divide (张量1，张量2)\n",
        "# 只有维度相同的张量才可以做四则运算\n",
        "\n",
        "a1 = tf.ones([1,3]) # 生成1行3列为1的张量\n",
        "b1 = tf.fill([1,3],3.) # 生成1行3列未3的张量\n",
        "\n",
        "print(\"张量相加：\",tf.add(a1,b1))\n",
        "print(\"张量相减：\",tf.subtract(a1,b1))\n",
        "print(\"张量相乘：\",tf.multiply(a1,b1))\n",
        "print(\"张量相除：\",tf.divide(a1,b1))\n",
        "\n",
        "# 计算某个张量的平方\n",
        "# tf.square (张量名) \n",
        "# 计算某个张量的n次方\n",
        "# tf.pow (张量名，n次方数)\n",
        "# 计算某个张量的开方\n",
        "# tf.sqrt (张量名）\n",
        "\n",
        "a3 = tf.fill([1,2],3.)\n",
        "\n",
        "print(\"a3的值：\",a3)\n",
        "\n",
        "print(\"求a3的平方：\",tf.square(a3))\n",
        "print(\"求a3的次方：\",tf.pow(a3,3))\n",
        "print(\"求a3的开方：\",tf.sqrt(a3))\n",
        "\n",
        "# 实现两个矩阵的相乘\n",
        "# tf.matmul(矩阵1，矩阵2)\n",
        "\n",
        "a4 = tf.ones([3,2])\n",
        "print(a4)\n",
        "b4 = tf.fill([2,3],3.)\n",
        "print(b4)\n",
        "print(\"两个矩阵的相乘:\",tf.matmul(a4,b4))\n",
        "\n",
        "# 切分传入张量的第一维度，生成输入特征/标签对，构建数据集\n",
        "# data = tf.data.Dataset.from_tensor_slices((输入特征, 标签))\n",
        "#（Numpy和Tensor格式都可用该语句读入数据）\n",
        "\n",
        "features = tf.constant([12,23,10,17])\n",
        "labels = tf.constant([0,1,1,0])\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
        "for element in dataset:\n",
        "    print(element) # 打印不出结果\n",
        "\n",
        "# tf.GradientTape\n",
        "# with结构记录计算过程，gradient求出张量的梯度\n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "  # 计算过程\n",
        "  w = tf.Variable(tf.constant(3.0))\n",
        "  loss = tf.pow(w,2)\n",
        "grad = tape.gradient(loss,w)\n",
        "print(\"对w进行求导：\",grad)\n",
        "\n",
        "# enumerate是python的内建函数，它可遍历每个元素(如列表、元组或字符串)，组合为：索引 元素，常在for循环中使用。\n",
        "\n",
        "seq = ['one','two','three']\n",
        "\n",
        "for i,element in enumerate(seq):\n",
        "  print(\"enumerate的使用：\",i,element)\n",
        "\n",
        "# tf.one_hot 独热编码（one-hot encoding）：在分类问题中，常用独热码做标签，标记类别：1表示是，0表示非。\n",
        "\n",
        "#（ 0狗尾草鸢尾 1杂色鸢尾 2弗吉尼亚鸢尾 ） 标 签： 1\n",
        "# 独热码： （0. 1. 0.）\n",
        "# tf.one_hot()函数将待转换数据，转换为one-hot形式的数据输出。\n",
        "# tf.one_hot (待转换数据, depth=几分类)\n",
        "\n",
        "classes = 3\n",
        "\n",
        "labels = tf.constant([1,0,2]) #  输入的元素值最小为0，最大为2\n",
        "output = tf.one_hot(labels,depth=classes)\n",
        "\n",
        "print(\"one_hot:\",output)\n",
        "\n",
        "# sotfmax 使输出符合概率分布\n",
        "\n",
        "y = tf.constant([1.01,2.01,-0.66])\n",
        "\n",
        "y_pro = tf.nn.softmax(y)\n",
        "\n",
        "print(\"After softmax, y_pro is:\", y_pro)\n",
        "\n",
        "# assign_sub \n",
        "# 赋值操作，更新参数的值并返回。\n",
        "# w.assign_sub (w要自减的内容)\n",
        "\n",
        "w1 = tf.Variable(4)\n",
        "w1.assign_sub(1)\n",
        "print(\"赋值操作：\",w1)\n",
        "\n",
        "# tf.argmax\n",
        "# 返回张量沿指定维度最大值的索引\n",
        "# tf.argmax (张量名,axis=操作轴)\n",
        "\n",
        "test = np.array([[1,2,3],[2,3,4],[8,7,2]])\n",
        "\n",
        "print(\"输出数组类型：\",test)\n",
        "\n",
        "print(tf.argmax(test,axis=0)) # 返回每一列（经度）最大值的索引\n",
        "print(tf.argmax(test,axis=1)) # 返回每一行（纬度）最大值的索引"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n",
            "输出张量的内容： tf.Tensor([1 5], shape=(2,), dtype=int64)\n",
            "输出张量的类型： <dtype: 'int64'>\n",
            "输出张量的形状： (2,)\n",
            "输出numpy类型： [0 1 2 3 4]\n",
            "将numpy类型转换成Tensor： tf.Tensor([0 1 2 3 4], shape=(5,), dtype=int64)\n",
            "创建一个两行三列的张量： tf.Tensor(\n",
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n",
            "创建四行为1的张量： tf.Tensor([1. 1. 1. 1.], shape=(4,), dtype=float32)\n",
            "创建两行两例为9的张量： tf.Tensor(\n",
            "[[9 9]\n",
            " [9 9]], shape=(2, 2), dtype=int32)\n",
            "生成截断式正态分布的随机数: tf.Tensor(\n",
            "[[0.11348999 0.44555753]\n",
            " [0.32937184 0.45427614]], shape=(2, 2), dtype=float32)\n",
            "生成值在均值附近的正态分布的随机数: tf.Tensor(\n",
            "[[0.3060819 1.6184272]\n",
            " [0.6121552 0.3950799]], shape=(2, 2), dtype=float32)\n",
            "生成均匀分布随机数: tf.Tensor(\n",
            "[[0.30975783 0.8702085 ]\n",
            " [0.5135678  0.16523707]], shape=(2, 2), dtype=float32)\n",
            "输出x1的结果： tf.Tensor([1. 2. 3.], shape=(3,), dtype=float64)\n",
            "强制转换成整型： tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
            "取出最小的值： tf.Tensor(1, shape=(), dtype=int32)\n",
            "取出最大的值： tf.Tensor(3, shape=(), dtype=int32)\n",
            "输出x的结果: tf.Tensor(\n",
            "[[1 2 3]\n",
            " [2 2 3]], shape=(2, 3), dtype=int32)\n",
            "求x的平均值: tf.Tensor(2, shape=(), dtype=int32)\n",
            "求x的总和: tf.Tensor([6 7], shape=(2,), dtype=int32)\n",
            "可训练的： <tf.Variable 'Variable:0' shape=(2, 2) dtype=float32, numpy=\n",
            "array([[0.34095308, 0.3589004 ],\n",
            "       [0.16678216, 1.0876632 ]], dtype=float32)>\n",
            "张量相加： tf.Tensor([[4. 4. 4.]], shape=(1, 3), dtype=float32)\n",
            "张量相减： tf.Tensor([[-2. -2. -2.]], shape=(1, 3), dtype=float32)\n",
            "张量相乘： tf.Tensor([[3. 3. 3.]], shape=(1, 3), dtype=float32)\n",
            "张量相除： tf.Tensor([[0.33333334 0.33333334 0.33333334]], shape=(1, 3), dtype=float32)\n",
            "a3的值： tf.Tensor([[3. 3.]], shape=(1, 2), dtype=float32)\n",
            "求a3的平方： tf.Tensor([[9. 9.]], shape=(1, 2), dtype=float32)\n",
            "求a3的次方： tf.Tensor([[27. 27.]], shape=(1, 2), dtype=float32)\n",
            "求a3的开方： tf.Tensor([[1.7320508 1.7320508]], shape=(1, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[1. 1.]\n",
            " [1. 1.]\n",
            " [1. 1.]], shape=(3, 2), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[3. 3. 3.]\n",
            " [3. 3. 3.]], shape=(2, 3), dtype=float32)\n",
            "两个矩阵的相乘: tf.Tensor(\n",
            "[[6. 6. 6.]\n",
            " [6. 6. 6.]\n",
            " [6. 6. 6.]], shape=(3, 3), dtype=float32)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=12>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=23>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=10>, <tf.Tensor: shape=(), dtype=int32, numpy=1>)\n",
            "(<tf.Tensor: shape=(), dtype=int32, numpy=17>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
            "对w进行求导： tf.Tensor(6.0, shape=(), dtype=float32)\n",
            "enumerate的使用： 0 one\n",
            "enumerate的使用： 1 two\n",
            "enumerate的使用： 2 three\n",
            "one_hot: tf.Tensor(\n",
            "[[0. 1. 0.]\n",
            " [1. 0. 0.]\n",
            " [0. 0. 1.]], shape=(3, 3), dtype=float32)\n",
            "After softmax, y_pro is: tf.Tensor([0.25598174 0.69583046 0.04818781], shape=(3,), dtype=float32)\n",
            "赋值操作： <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=3>\n",
            "输出数组类型： [[1 2 3]\n",
            " [2 3 4]\n",
            " [8 7 2]]\n",
            "tf.Tensor([2 2 1], shape=(3,), dtype=int64)\n",
            "tf.Tensor([2 2 0], shape=(3,), dtype=int64)\n"
          ]
        }
      ]
    }
  ]
}